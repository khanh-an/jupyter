import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_curve, auc
from sklearn.multiclass import OneVsRestClassifier
from sklearn.ensemble import RandomForestClassifier  
from sklearn.feature_extraction.text import TfidfVectorizer
import seaborn as sns
import matplotlib.pyplot as plt
import streamlit as st

# ===============================
# ===============================
file_path = "Databds_CT1.csv"

try:
    df = pd.read_csv(file_path)
    print("‚úÖ File CSV ƒë√£ ƒë∆∞·ª£c ƒë·ªçc th√†nh c√¥ng. D·ªØ li·ªáu ƒë·∫ßu ti√™n:")
    print(df.head().to_markdown(index=False))
except FileNotFoundError:
    print(f"‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file '{file_path}'.")
    df = pd.DataFrame()  # t·∫°o DataFrame r·ªóng ƒë·ªÉ tr√°nh l·ªói ti·∫øp theo
except Exception as e:
    print(f"‚ùå L·ªói khi ƒë·ªçc file: {e}")
    df = pd.DataFrame()

# ===============================
# Ki·ªÉm tra df c√≥ d·ªØ li·ªáu kh√¥ng
# ===============================
if df.empty:
    print("‚ùå DataFrame r·ªóng. Kh√¥ng th·ªÉ ti·∫øp t·ª•c x·ª≠ l√Ω d·ªØ li·ªáu.")
else:
    #  ƒêi·ªÅn khuy·∫øt v√† chu·∫©n h√≥a c·ªôt ƒë·ªãa l√Ω 
    for col, default in [('ward', 'Ch∆∞a r√µ Ph∆∞·ªùng'),
                         ('district', 'Ch∆∞a r√µ Qu·∫≠n/Huy·ªán'),
                         ('province', 'Unknown')]:
        if col in df.columns:
            df[col] = df[col].fillna(default)
            df[col] = df[col].astype(str).str.strip().str.title()

    #  Chu·∫©n h√≥a 'property_type' 
    if 'property_type' in df.columns:
        df['property_type'] = df['property_type'].astype(str).str.strip().str.title()

    #  ƒêi·ªÅn khuy·∫øt v√† t·∫°o c·ªôt is_company 
    if 'company_post' in df.columns:
        df['company_post'] = df['company_post'].fillna('Personal/Unknown')
        df['company_post'] = df['company_post'].astype(str).str.strip()
        df['is_company'] = df['company_post'].apply(lambda x: 0 if x in ['Personal/Unknown','Individual/Unknown'] else 1)

    #  4. X·ª≠ l√Ω c·ªôt 'title' 
    if 'title' in df.columns:
        df['title'] = df['title'].fillna('')
        df['title_length'] = df['title'].apply(len)
        df['is_hot_listing'] = df['title'].str.contains('HOT|Gi√° T·ªët|C·∫ßn B√°n G·∫•p', case=False, na=False).astype(int)

    #  5. X·ª≠ l√Ω c·ªôt 'description' 
    if 'description' in df.columns:
        df['description'] = df['description'].fillna('')
        df['content_length'] = df['description'].apply(len)
        df['has_legal_documents'] = df['description'].str.contains('s·ªï h·ªìng|s·ªï ƒë·ªè|ph√°p l√Ω r√µ r√†ng', case=False, na=False).astype(int)

    #  6. TF-IDF cho 'title' 
    if 'title' in df.columns:
        tfidf_title = TfidfVectorizer(max_features=500)
        X_title = tfidf_title.fit_transform(df['title'])
        df_title_tfidf = pd.DataFrame(X_title.toarray(), columns=tfidf_title.get_feature_names_out())
        df = pd.concat([df.reset_index(drop=True), df_title_tfidf.reset_index(drop=True)], axis=1)
        df.drop('title', axis=1, inplace=True)

    #  7. TF-IDF cho 'description' 
    if 'description' in df.columns:
        tfidf_desc = TfidfVectorizer(max_features=1000)
        X_desc = tfidf_desc.fit_transform(df['description'])
        df_desc_tfidf = pd.DataFrame(X_desc.toarray(), columns=tfidf_desc.get_feature_names_out())
        df = pd.concat([df.reset_index(drop=True), df_desc_tfidf.reset_index(drop=True)], axis=1)
        df.drop('description', axis=1, inplace=True)

    #  8. Chuy·ªÉn bool/int sang float 
    bool_cols = df.select_dtypes(include=['bool']).columns.tolist()
    df[bool_cols] = df[bool_cols].astype(float)

    int_cols = df.select_dtypes(include=['int64', 'int32']).columns.tolist()
    df[int_cols] = df[int_cols].astype(float)

    #  9. Fillna cho object c√≤n l·∫°i 
    object_cols = df.select_dtypes(include=['object']).columns.tolist()
    df[object_cols] = df[object_cols].fillna('')

    #  10. Chu·∫©n h√≥a t√™n c·ªôt 
    df.columns = [col.strip().lower() for col in df.columns]

    #  11. X·ª≠ l√Ω th·ªùi gian t·ª´ actual_date 
    if 'actual_date' in df.columns:
        df['actual_date'] = pd.to_datetime(df['actual_date'], errors='coerce')
        df['actual_year'] = df['actual_date'].dt.year
        df['actual_month'] = df['actual_date'].dt.month
        df['actual_weekday'] = df['actual_date'].dt.dayofweek
        df.drop('actual_date', axis=1, inplace=True)

    #  12. T·∫°o t·∫ßn su·∫•t district/ward 
    if 'district' in df.columns:
        district_counts = df['district'].value_counts(normalize=True)
        df['district_frequency'] = df['district'].map(district_counts)

    if 'ward' in df.columns:
        ward_counts = df['ward'].value_counts(normalize=True)
        df['ward_frequency'] = df['ward'].map(ward_counts)

    #  13. One-Hot Encoding cho property_type 
    if 'property_type' in df.columns:
        df_property_encoded = pd.get_dummies(df['property_type'], prefix='property_type')
        df = pd.concat([df, df_property_encoded], axis=1)
        df.drop('property_type', axis=1, inplace=True)

    print("‚úÖ Pipeline x·ª≠ l√Ω d·ªØ li·ªáu ho√†n t·∫•t. D·ªØ li·ªáu hi·ªán t·∫°i:")
    print(df.head().to_markdown(index=False))
object_cols = df.select_dtypes(include=['object']).columns.tolist()

if len(object_cols) == 0:
    print("‚úÖ Kh√¥ng c√≤n c·ªôt object n√†o trong df.")
else:
    print("V·∫´n c√≤n c√°c c·ªôt object:", object_cols)  
import re
def clean_column_names(df):
    new_cols = []
    for col in df.columns:
        col_new = re.sub(r'[^a-z0-9_]+', '_', col.lower()).strip('_')
        new_cols.append(col_new)
    df.columns = new_cols
    return df

df = clean_column_names(df)
# C√°c c·ªôt c·∫ßn gi·ªØ l·∫°i
columns_to_keep = [
    'price', 'price_per_m2_million', 'list_time', 'longitude', 'latitude', 'area',
    'num_rooms', 'num_toilets', 'contain_videos', 'is_pinned', 'num_images',
    'rating_score', 'sold_status', 'title_length', 'content_length', 'posting_year',
    'posting_month', 'posting_weekday', 'district_frequency', 'ward_frequency',
    'project_frequency', 'district'
]

# Ch·ªâ gi·ªØ l·∫°i c√°c c·ªôt c√≥ t·ªìn t·∫°i trong DataFrame
columns_existing = [c for c in columns_to_keep if c in df.columns]

# T·∫°o df_valid ƒë·ªÉ ki·ªÉm tra d·ªØ li·ªáu th√¥
df_valid = df[columns_existing].copy()

print("C√°c c·ªôt ƒë∆∞·ª£c gi·ªØ:", columns_existing)

# C√°c c·ªôt d√πng cho m√¥ h√¨nh outlier detection
model_cols = [
    'price', 'price_per_m2_million', 'area',
    'num_rooms', 'num_toilets', 'num_images',
    'rating_score', 'title_length', 'content_length',
    'district_frequency', 'ward_frequency', 'project_frequency'
]
cols_price = [
    'price', 'price_per_m2_million', 'area', 'num_rooms', 'num_toilets',
    'num_images', 'rating_score', 'contain_videos', 'is_pinned',
    'title_length', 'content_length', 'district_frequency', 'ward_frequency'
]
# L·ªçc theo c√°c c·ªôt m√¥ h√¨nh (v√† ch·ªâ l·∫•y nh·ªØng c·ªôt ƒëang t·ªìn t·∫°i)
model_cols_existing = [c for c in model_cols if c in df.columns]

df_model = df[model_cols_existing].copy()

# Thay NaN b·∫±ng 0
df_model = df_model.fillna(0)
df_price = df[cols_price].copy()
df_price = df_price.fillna(0)
print("C√°c c·ªôt m√¥ h√¨nh:", model_cols_existing)
if "district" in df.columns and "price" in df.columns:
    district_price_mean = df.groupby("district")["price"].mean()
    df_valid["price_by_district"] = df["district"].map(district_price_mean)

if "district" in df.columns and "price_per_m2_million" in df.columns:
    district_price_m2_mean = df.groupby("district")["price_per_m2_million"].mean()
    df_valid["price_per_m2_by_district"] = df["district"].map(district_price_m2_mean)if 'price_by_district' in df_valid.columns:
    district_price = (
        df_valid[['district', 'price_by_district']]
        .drop_duplicates()
        .sort_values('price_by_district', ascending=False)
    )

    plt.figure(figsize=(12,6))
    colors = plt.cm.viridis(np.linspace(0, 1, len(district_price)))

    bars = plt.bar(district_price['district'], district_price['price_by_district'],
                   color=colors)

    for bar in bars:
        h = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2, h, 
                 f'{h:.0f}', ha='center', va='bottom', fontsize=9)

    plt.xticks(rotation=45)
    plt.title("Gi√° trung b√¨nh theo district")
    plt.ylabel("Gi√° trung b√¨nh")
    plt.xlabel("District")
    plt.tight_layout()
    plt.show()
if 'price_per_m2_by_district' in df_valid.columns:
    district_price_m2 = (
        df_valid[['district', 'price_per_m2_by_district']]
        .drop_duplicates()
        .sort_values('price_per_m2_by_district', ascending=False)
    )

    plt.figure(figsize=(12,6))
    colors = plt.cm.magma(np.linspace(0, 1, len(district_price_m2)))

    bars = plt.bar(district_price_m2['district'], district_price_m2['price_per_m2_by_district'],
                   color=colors)

    for bar in bars:
        h = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2, h, 
                 f'{h:.1f}', ha='center', va='bottom', fontsize=9)

    plt.xticks(rotation=45)
    plt.title("Gi√° trung b√¨nh / m2 theo district")
    plt.ylabel("Gi√° trung b√¨nh / m2 (tri·ªáu)")
    plt.xlabel("District")
    plt.tight_layout()
    plt.show()df_valid = df_valid.dropna(subset=['sold_status'])

X = df_valid.drop('sold_status', axis=1)
y = df_valid['sold_status'].astype(int)
X_num = X.select_dtypes(include=['int', 'float'])
plt.figure(figsize=(12,10))
corr = X_num.corr()
sns.heatmap(corr, annot=False, cmap='coolwarm')
plt.title("Heatmap ma tr·∫≠n t∆∞∆°ng quan gi·ªØa c√°c feature (numeric)")
plt.show()
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X = scaler.fit_transform(df_model)from sklearn.ensemble import IsolationForest

iso = IsolationForest(
    n_estimators=300,
    contamination=0.03,       
    random_state=42
)

df['outlier_score'] = iso.fit_predict(X)
df['anomaly'] = df['outlier_score'].apply(lambda x: 'Outlier' if x == -1 else 'Normal')
  df['anomaly'].value_counts()
df_out = df[df['anomaly'] == 'Outlier']
df_out.head(20)
df['price'] = df['price'].astype('int64')
# H√†m x√°c ƒë·ªãnh l√Ω do b·∫•t th∆∞·ªùng
def reason(row):
    reasons = []

    if row['price'] < df['price'].quantile(0.05):
        reasons.append("Gi√° qu√° th·∫•p")
    if row['price'] > df['price'].quantile(0.95):
        reasons.append("Gi√° qu√° cao")

    if row['area'] < df['area'].quantile(0.05) and row['price'] > df['price'].quantile(0.80):
        reasons.append("Di·ªán t√≠ch nh·ªè nh∆∞ng gi√° cao")

    if row['content_length'] < 80 and row['price'] > df['price'].quantile(0.75):
        reasons.append("N·ªôi dung ng·∫Øn nh∆∞ng gi√° cao")

    if row['num_images'] <= 1 and row['price'] > df['price'].quantile(0.70):
        reasons.append("√çt h√¨nh ·∫£nh nh∆∞ng gi√° cao")

    return ", ".join(reasons) if reasons else "Kh√¥ng r√µ"

# L·ªçc Outlier
df_out = df[df['anomaly'] == 'Outlier'].copy()

# G√°n l√Ω do b·∫•t th∆∞·ªùng
df_out.loc[:, 'reason'] = df_out.apply(reason, axis=1)

# Ch·ªâ hi·ªÉn th·ªã nh·ªØng c·ªôt c√≥ th·∫≠t trong df_out
columns_to_show = ['price', 'area', 'num_images', 'content_length', 'district', 'ward', 'project_name', 'reason']
columns_existing = [c for c in columns_to_show if c in df_out.columns]

# Hi·ªÉn th·ªã b·∫£ng
df_out[columns_existing].head(10)
plt.figure(figsize=(10,5))
plt.hist(df['price'], bins=50, alpha=0.7, color='blue', label='Normal')
plt.hist(df_out['price'], bins=50, alpha=0.7, color='red', label='Outlier')
plt.xlabel("Gi√° (VNƒê)")
plt.ylabel("S·ªë l∆∞·ª£ng b√†i ƒëƒÉng")
plt.title("Ph√¢n b·ªë gi√° - Outlier vs Normal")
plt.legend()
plt.show()
corr_matrix = df_price.corr()
plt.figure(figsize=(8,5))
sns.boxplot(x='num_rooms', y='price', data=df_price)
plt.title("Gi√° theo s·ªë ph√≤ng")
plt.show()
plt.figure(figsize=(8,5))
sns.boxplot(x='contain_videos', y='price', data=df_price)
plt.title("Gi√° theo vi·ªác c√≥ video")
plt.show()
plt.figure(figsize=(8,5))
sns.scatterplot(x='district_frequency', y='price', data=df_price, alpha=0.6)
plt.title("Gi√° theo district_frequency")
plt.show()
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import OneHotEncoder

# X, y
X = df_price.drop(['price','price_per_m2_million'], axis=1)
y = df_price['price']

X['contain_videos'] = X['contain_videos'].astype(int)
X['is_pinned'] = X['is_pinned'].astype(int)

# Random Forest
rf = RandomForestRegressor(n_estimators=300, random_state=42)
rf.fit(X, y)

# Feature importance
feat_imp = pd.DataFrame({'feature': X.columns, 'importance': rf.feature_importances_}).sort_values(by='importance', ascending=False)
print(feat_imp)

plt.figure(figsize=(10,5))
sns.barplot(x='importance', y='feature', data=feat_imp)
plt.title("Y·∫øu t·ªë ·∫£nh h∆∞·ªüng ƒë·∫øn gi√° BƒêS")
plt.show()
from cassandra.cluster import Cluster
import time
import uuid
import pandas as pd

cassandra_hosts = ["cassandra-db"]   # ho·∫∑c ["127.0.0.1"]
keyspace = "mykeyspace"
table = "real_estate_price"

max_retries = 12
retry_delay = 5

cluster = None
for attempt in range(1, max_retries+1):
    try:
        cluster = Cluster(contact_points=cassandra_hosts, port=9042)
        session = cluster.connect()
        print(f"‚úÖ Connected to Cassandra (attempt {attempt})")
        break
    except Exception as e:
        print(f"‚ö†Ô∏è Kh√¥ng k·∫øt n·ªëi ƒë∆∞·ª£c (attempt {attempt}): {e}")
        time.sleep(retry_delay)

if cluster is None:
    raise SystemExit("‚ùå Kh√¥ng th·ªÉ k·∫øt n·ªëi Cassandra")

session.execute(f"""
CREATE KEYSPACE IF NOT EXISTS {keyspace}
WITH replication = {{'class': 'SimpleStrategy', 'replication_factor': 1}}
""")

session.set_keyspace(keyspace)
columns_to_keep = [
    'price', 'price_per_m2_million', 'list_time', 'longitude', 'latitude', 'area',
    'num_rooms', 'num_toilets', 'contain_videos', 'is_pinned', 'num_images',
    'rating_score', 'sold_status', 'title_length', 'content_length',
    'posting_year', 'posting_month', 'posting_weekday',
    'district_frequency', 'ward_frequency', 'project_frequency', 'district'
]

columns_existing = [c for c in columns_to_keep if c in df.columns]
df_insert = df[columns_existing].copy()

# Cassandra kh√¥ng nh·∫≠n NaN
df_insert = df_insert.where(df_insert.notnull(), None)

print("‚úÖ Columns insert:", df_insert.columns.tolist())
print("‚úÖ Rows:", len(df_insert))
session.execute(f"""
CREATE TABLE IF NOT EXISTS {table} (
    id UUID,
    district TEXT,
    posting_year INT,

    price DOUBLE,
    price_per_m2_million DOUBLE,
    area DOUBLE,
    num_rooms INT,
    num_toilets INT,
    num_images INT,
    rating_score DOUBLE,
    contain_videos INT,
    is_pinned INT,
    title_length INT,
    content_length INT,
    district_frequency DOUBLE,
    ward_frequency DOUBLE,
    project_frequency DOUBLE,

    PRIMARY KEY ((district, posting_year), id)
)
""")

print("‚úÖ Table Cassandra s·∫µn s√†ng")
insert_cql = f"""
INSERT INTO {table} (
    id, district, posting_year,
    price, price_per_m2_million, area,
    num_rooms, num_toilets, num_images,
    rating_score, contain_videos, is_pinned,
    title_length, content_length,
    district_frequency, ward_frequency, project_frequency
)
VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
"""

prepared = session.prepare(insert_cql)
import math

def i(x): 
    return 0 if x is None or (isinstance(x, float) and math.isnan(x)) else int(x)

def f(x): 
    return 0.0 if x is None or (isinstance(x, float) and math.isnan(x)) else float(x)
for _, row in df_insert.iterrows():
    session.execute(prepared, (
        uuid.uuid4(),
        row.get('district'),
        i(row.get('posting_year')),

        f(row.get('price')),
        f(row.get('price_per_m2_million')),
        f(row.get('area')),

        i(row.get('num_rooms')),
        i(row.get('num_toilets')),
        i(row.get('num_images')),

        f(row.get('rating_score')),
        i(row.get('contain_videos')),
        i(row.get('is_pinned')),

        i(row.get('title_length')),
        i(row.get('content_length')),

        f(row.get('district_frequency')),
        f(row.get('ward_frequency')),
        f(row.get('project_frequency'))
    ))
print("üéâ ƒê√É GHI XONG DATAFRAME V√ÄO CASSANDRA")
rows = session.execute(f"""
SELECT district, posting_year, price
FROM {table}
LIMIT 5
""")

for r in rows:
    print(r)
rows = session.execute("""
SELECT table_name
FROM system_schema.tables
WHERE keyspace_name = 'mykeyspace'
""")

for r in rows:
    print(r.table_name)
import streamlit as st
from cassandra.cluster import Cluster
import pandas as pd

cluster = Cluster(['cassandra-db'])
session = cluster.connect('real_estate')

rows = session.execute("SELECT * FROM listings")

df = pd.DataFrame(list(rows))
st.title("üè† D·ª± ƒëo√°n gi√° b·∫•t ƒë·ªông s·∫£n")
st.dataframe(df)
